<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation.">
  <meta name="keywords" content="Surface-SOS, Segmentation, NeuS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--   <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
        .container-h {
            width: 90%; /* 或者根据需要设置为其他宽度 */
            margin: auto; /* 居中显示 */
        }

  </style>

    <style>
        .fixed-size-video {
            width: 950px; /* 设置视频的固定宽度 */
            height: auto; /* 设置视频的固定高度 */
            margin: auto; /* 居中显示 */
        }
    </style>

    <style>
        .fixed-size-video-small {
            width: 700px; /* 设置视频的固定宽度 */
            height: auto; /* 设置视频的固定高度 */
        }
        .rounded-corners {
    border-radius: 10px; /* 设置圆角的大小 */
  }
    </style>
    <style>
        .video-container {
            height: 600px; /* 统一设置视频高度 */
            width: auto;   /* 宽度自适应 */
        }
    </style>
    <style>
        .video-container {
            display: flex;         /* 使用 flexbox 布局 */
            justify-content: center; /* 水平居中 */
        }
        .video-container video {
            width: 30%;           /* 每个视频宽度占容器的30% */
            margin: 5px;          /* 视频之间的间隔 */
        }
    </style>

<style>
  .video-row {
    display: flex;
    justify-content: space-around; /* 可以改为 center 使得视频在行中居中 */
    margin-bottom: 20px; /* 行与行之间的间距 */
  }

  .fixed-size-video-small {
    width: 33%; /* 设置视频的固定宽度 */
            height: auto; /* 设置视频的固定高度 */
  }
  .fixed-size-video-small-two {
    width: 800px; /* 设置视频的固定宽度 */
            height: auto; /* 设置视频的固定高度 */
  }
  .fixed-size-video-small-three {
    width: 1340px; /* 设置视频的固定宽度 */
            height: auto; /* 设置视频的固定高度 */
  }
  
  /* 可能需要调整的样式 */
  @media screen and (max-width: 768px) {
    /* 在较小屏幕上，让视频堆叠而不是并排 */
    .video-row {
      flex-direction: column;
    }
  }
</style>

<style>
        .text-container {
            max-width: 1070px; /* 限制文本容器的最大宽度 */
            margin: 0 auto;    /* 居中文本容器 */
            padding: 20px;     /* 为容器添加一些内边距 */
        }
        
</style>
  
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/zhengxyun">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://pku-dymvhumans.github.io">
            PKU-DyMVHumans
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhengxyun.github.io">XiaoyunZheng</a><sup>1, 2</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/leviome">Liwei Liao</a><sup>1, 2</sup>,</span>
            <span class="author-block">
              <a href="https://jianbojiao.com">Jianbo Jiao</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://www.art.pku.edu.cn/szdw/qzjs/cysjyysglx/gf/index.htm">Feng Gao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.ece.pku.edu.cn/info/1046/2147.htm">Ronggang Wang</a><sup>1*</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Peking University</span>
            <span class="author-block"><sup>2</sup>Peng Cheng Laboratory</span>
            <span class="author-block"><sup>3</sup>University of Birmingham</span>
          </div>

          <div class="is-size-4 publication">
            <span class="author-block"> </span>
            <span class="author-block"> TIP 2024 </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/abstract/document/10471326"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zhengxyun/Surface-SOS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video class="fixed-size-video" width="100%" id="ablation1" loop="" playsinline="" autoplay="" muted="" src="./static/videos/daily_cat_it30k_res.mp4" onplay="resizeAndPlay(this)"></video>
      
<!--       <video class="fixed-size-video rounded-corners" id="supp video" autoplay loop muted playsinline controls>
          <source src="./static/videos/daily_cat_it30k_res.mp4" type="video/mp4">
      </video> -->
      <p style="font-size:17px;">
         We present a self-supervised approach for delicate segmentation from multi-view images 
        that are geometrically consistent.
      </p>
    </div>
  </div>

</section>


<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Self-supervised Object Segmentation (SOS) aims to segment objects without any annotations. 
            Under conditions of multi-camera inputs, the structural, textural and geometrical consistency among each view 
            can be leveraged to achieve fine-grained object segmentation. 
          </p>
          <p>
            To make better use of the above information, we propose Surface representation based Self-supervised Object Segmentation (Surface-SOS), 
            a new framework to segment objects for each view by 3D surface representation from multi-view images of a scene. 
          </p>
          <p>
            To model high-quality geometry surfaces for complex scenes, we design a novel scene representation scheme, 
            which decomposes the scene into two complementary neural representation modules respectively with a Signed Distance Function (SDF).
            Moreover, Surface-SOS is able to refine single-view segmentation with multi-view unlabeled images, 
            by introducing coarse segmentation masks as additional input. 
          </p>
          <p>
            To the best of our knowledge, Surface-SOS is the first self-supervised approach that leverages neural surface representation 
            to break the dependence on large amounts of annotated data and strong constraints. 
            These constraints typically involve observing target objects against a static background or relying on temporal supervision in videos. 
          </p>
          <p>
            Extensive experiments on standard benchmarks including LLFF, CO3D, BlendedMVS, TUM and several real-world scenes show that 
            Surface-SOS always yields finer object masks than its NeRF-based counterparts 
            and surpasses supervised single-view baselines remarkably. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->

  
<br><br>

<div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Method Overview</h2>
</div>
  
<div class="container is-max-desktop">
      <div class="hero-body">
        <div class="content has-text-justified">
          <img src="./static/images/overview.png"> 

          <p>
            <b> Framework.</b> For the scene captured by N images, we use COLMAP and Mask-RCNN to get sparse 3D points 
            and coarse object masks as co-inputs, and predict a dense, geometrical consistent object map, 
            as well as a textural, completed background for each image. 
            To tackle this challenging task by leveraging the existence of geometric consistency of the one-to-one dense mapping in 3D space, 
            we decouple the scene into two complementary neural scene representation modules: 
            a Foreground Consistent Representation (FoCoR) module and a Background Completion (BaCo) module. 
            We build our scene representation modules upon the SDF-based neural surface representation, 
            and incorporate multi-resolution hash encodings for training acceleration. 
          </p>
          
        </div>
    </div>
</div>

<br><br>

<div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Results</h2>
</div>
  
<div class="container is-max-desktop">
      <div class="hero-body">
        <div class="content has-text-justified">
          <img src="./static/images/visual.png"> 

          <p>
            Visualizations details of mask and RGB rendering results at the high-resolution of 3840×2160.
          </p>
          
        </div>
    </div>
</div>

  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @ARTICLE{zxyun@surfacesos,
          author={Zheng, Xiaoyun and Liao, Liwei and Jiao, Jianbo and Gao, Feng and Wang, Ronggang},
          journal={IEEE Transactions on Image Processing}, 
          title={Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation}, 
          year={2024},
          volume={33},
          pages={2018-2031}}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/zhengxyun/Surface-SOS" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website template is based on <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
